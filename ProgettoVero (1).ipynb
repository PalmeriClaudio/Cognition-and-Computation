{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Claudio Palmeri 2062671 02/22/2023\n",
        "\n",
        "\n",
        "My project will be focused around the EMNIST dataset, a dataset similar to the MNIST dataset. This is a classification tasks where we try to differentiate between handwritten letters (in contrast with the MNIST dataset that contains handwritten digits).\n",
        "\n",
        "\n",
        "First of all I have to import all the relevant libraries and the files that professor Alberto Testolin used during our course."
      ],
      "metadata": {
        "id": "AzBmwh9AT3IN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0Yvw1ttB9TG"
      },
      "outputs": [],
      "source": [
        "def _get_files_from_repo(files, repo):\n",
        "  repository_url = f\"https://raw.githubusercontent.com/flavio2018/{repo}/master/\"\n",
        "  for file in files:\n",
        "    ! wget -O {file} {repository_url}{file}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "files = [\"DBN.py\", \"RBM.py\"]\n",
        "_get_files_from_repo(files, \"Deep-Belief-Network-pytorch\")"
      ],
      "metadata": {
        "id": "VNrWi1XLCE0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.cluster as cluster\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn.functional as functional\n",
        "import torchvision as tv\n",
        "\n",
        "from DBN import DBN\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "BrPxxH0HCJx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b5349758-5df3-45a3-e004-2d262a8602ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ceb5899924b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: <EMPTY MESSAGE>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most efficient (and thus fastest) way to handle the processing of our data is by using a GPU, with the following instruction we check if this is possible in the current eviroment."
      ],
      "metadata": {
        "id": "I8_iZsx2aC81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "id": "79d6nIoVCNPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We proceed now to download the EMNIST dataset that consist in 145600 28x28 gray scale images.\n",
        "\n",
        "In order to be able to compute the accuracy of our models we need to separate our dataset in a training and a test set. We don't need to add additional instructions in order to obtain this separation since the developers of the library torch added the argument \"train\".\n",
        "\n",
        "This boolean variable decides whether we are considering the training set (train=True, 124800 images) or the test set (train=False, 20800 images).\n",
        "\n",
        "Since we are using a gray scale, every value in our datasets will be an integer included in the interval [0,255].  \n",
        "In order to get better perfomances in our models I decided to divide each value by 255, this way we will only have values belonging to the interval [0,1]."
      ],
      "metadata": {
        "id": "-P09qkh7anoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_train=tv.datasets.EMNIST('data/', train=True ,download=True,split=\"letters\")\n",
        "emnist_test=tv.datasets.EMNIST('data/', train=False ,download=True,split=\"letters\")\n",
        "emnist_train.data = (emnist_train.data.type(torch.FloatTensor)/255)\n",
        "emnist_test.data = (emnist_test.data.type(torch.FloatTensor)/255)"
      ],
      "metadata": {
        "id": "xVDn3PYNCQc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before creating our models, i decided to print some examples of the images.\n",
        "\n",
        "By doing this I observed 2 things:  \n",
        "  \n",
        "* In order to plot the images with the correct orientation (i.e. the one us humans are more familiar with) I was forced to both plot the transpose of the original image and also to change the orientation of the y-axis.\n",
        "\n",
        "* Since our classes are expressed with a number between 1 and 26, I created an array containing the letters of the alphabet. This way we don't have to manually count the letters to understand which class the current image belongs to."
      ],
      "metadata": {
        "id": "5OyXYdXXbe19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alfa=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"The letter shown is the letter: {}\".format(  alfa[emnist_train.targets[i]-1]   ) )\n",
        "  plt.imshow(emnist_train.data[i].T, cmap = 'gray')\n",
        "  plt.axis([0,27,27,0])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "bWAObfCCLbe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then transfer our datasets to the GPU device in order to make our training process quicker."
      ],
      "metadata": {
        "id": "rn-z4yAwcr-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_train.data = emnist_train.data.to(device)\n",
        "emnist_test.data = emnist_test.data.to(device)\n",
        "emnist_train.targets = emnist_train.targets.to(device)\n",
        "emnist_test.targets = emnist_test.targets.to(device)"
      ],
      "metadata": {
        "id": "GkmhtOrWQ729"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can begin now to train some models on our dataset.\n",
        "The first one we will consider is a deep belief network (DBN). This is an unsupervised deep learning model and thus by itself it can't be used for our classification task.\n",
        "\n",
        "A DBN is simply a stack of restricted Boltzman machines (RBM) that can be trained with contrastive divergence either together or one by one (the parameter k is the number of RBM trained at the same time).\n",
        "We want to minimize the difference between the empirical data and the patterns generated by the network.\n",
        "\n",
        "This is computationally expensive but can be approximated by using the distortions of the original data: We basically insert our data at the bottom of our DBN, we compute the neuron activations by going up until the last level and then we go in the opposite direction. Ideally we want to reconstruct the original input and we this doesn't happen we adjust the weights of our network accordingly."
      ],
      "metadata": {
        "id": "9mYjwzfmc1Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_emnist = DBN(visible_units=28*28,\n",
        "                hidden_units=[400, 600, 800, 1000],\n",
        "                k=1,\n",
        "                learning_rate=0.1,\n",
        "                learning_rate_decay=False,\n",
        "                initial_momentum=0.5,\n",
        "                final_momentum=0.95,\n",
        "                weight_decay=0.0001,\n",
        "                xavier_init=False,\n",
        "                increase_to_cd_k=False,\n",
        "                use_gpu=torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "3Hij5DAFRVX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "batch_size = 125\n",
        "\n",
        "dbn_emnist.train_static(\n",
        "    emnist_train.data,\n",
        "    emnist_train.targets,\n",
        "    num_epochs,\n",
        "    batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "xycnKdSGRacN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After having trained our DBN, our hope is that the neurons in the deepest layers have picked up some of the characteristics of our datasets.  \n",
        "\n",
        "In order to check that we can visualize the weights of our models that are called receptive fields.\n",
        "\n",
        "Before doing that we need to:\n",
        "* apply threshold to reduce noise\n",
        "* apply a min max scaler to fairly compare different receptive fields\n",
        "* eventually projecting them in a lower dimensional space"
      ],
      "metadata": {
        "id": "HEIkUzWjRB-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights(dbn, layer):\n",
        "  return dbn.rbm_layers[layer].W.cpu().numpy()\n",
        "\n",
        "def apply_threshold(weights, threshold=0):\n",
        "  return weights * (abs(weights) > threshold)\n",
        "\n",
        "def plot_layer_receptive_fields(weights):\n",
        "  num_subplots = 100\n",
        "  n_rows_cols = int(math.sqrt(num_subplots))\n",
        "  fig, axes = plt.subplots(n_rows_cols, n_rows_cols, sharex=True, sharey=True, figsize=(10, 10))\n",
        "  for i in range(num_subplots):\n",
        "    row = i % n_rows_cols\n",
        "    col = i // n_rows_cols\n",
        "    axes[row, col].imshow(weights[i,:].reshape((28,28)), cmap=plt.cm.gray)  # here we select the weights we want to plot\n",
        "\n",
        "def apply_min_max_scaler(learned_weights):\n",
        "  original_shape = learned_weights.shape\n",
        "  min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "  min_max_scaled_learned_weights = min_max_scaler.fit_transform(learned_weights.ravel().reshape(-1,1))\n",
        "  min_max_scaled_learned_weights = min_max_scaled_learned_weights.reshape(original_shape)\n",
        "  return min_max_scaled_learned_weights"
      ],
      "metadata": {
        "id": "Nx-HMFE3Ujw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learned_weights_layer_1 = get_weights(dbn_emnist, layer=0)\n",
        "#learned_weights_layer_1 = apply_threshold(learned_weights_layer_1, .1)\n",
        "#learned_weights_layer_1 = apply_min_max_scaler(learned_weights_layer_1)\n",
        "\n",
        "#plot_layer_receptive_fields(learned_weights_layer_1.T)"
      ],
      "metadata": {
        "id": "ogIVyOJ1Uo-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learned_weights_layer_1 = get_weights(dbn_emnist, layer=0)\n",
        "learned_weights_layer_2 = get_weights(dbn_emnist, layer=1)\n",
        "learned_weights_layer_3 = get_weights(dbn_emnist, layer=2)\n",
        "learned_weights_layer_4 = get_weights(dbn_emnist, layer=3)\n",
        "\n",
        "learned_weights_layer_1 = apply_threshold(learned_weights_layer_1, 0.1)\n",
        "learned_weights_layer_2 = apply_threshold(learned_weights_layer_2, 0.1)\n",
        "learned_weights_layer_3 = apply_threshold(learned_weights_layer_3, 0.1)\n",
        "learned_weights_layer_4 = apply_threshold(learned_weights_layer_4, 0.1)\n",
        "\n",
        "learned_weights_layer_1 = apply_min_max_scaler(learned_weights_layer_1)\n",
        "learned_weights_12_product = (learned_weights_layer_1 @ learned_weights_layer_2)  # here we do the projection (matrix multiplication)\n",
        "learned_weights_23_product = (learned_weights_12_product @ learned_weights_layer_3)  # here we do the projection\n",
        "learned_weights_34_product = (learned_weights_23_product @ learned_weights_layer_4)\n",
        "learned_weights_12_product = apply_threshold(learned_weights_12_product, 0.1)\n",
        "learned_weights_12_product = apply_min_max_scaler(learned_weights_12_product)\n",
        "learned_weights_23_product = apply_threshold(learned_weights_23_product, 0.1)\n",
        "learned_weights_23_product = apply_min_max_scaler(learned_weights_23_product)\n",
        "learned_weights_34_product = apply_threshold(learned_weights_34_product, 0.1)\n",
        "learned_weights_34_product = apply_min_max_scaler(learned_weights_34_product)\n",
        "\n",
        "plot_layer_receptive_fields(learned_weights_layer_1.T)\n",
        "\n"
      ],
      "metadata": {
        "id": "2TIX6YCoSm7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_layer_receptive_fields(learned_weights_12_product.T)"
      ],
      "metadata": {
        "id": "CYS5tv-sV4pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_layer_receptive_fields(learned_weights_23_product.T)"
      ],
      "metadata": {
        "id": "v7hRTnnaV7Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_layer_receptive_fields(learned_weights_34_product.T)"
      ],
      "metadata": {
        "id": "rfpi5z_fdpk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learned_weights_layer_1 = get_weights(dbn_emnist, layer=0)\n",
        "#learned_weights_layer_2 = get_weights(dbn_emnist, layer=1)\n",
        "\n",
        "###learned_weights_layer_1 = apply_threshold(learned_weights_layer_1, 0.1)\n",
        "#learned_weights_layer_2 = apply_threshold(learned_weights_layer_2, 0.1)\n",
        "\n",
        "#learned_weights_product = (learned_weights_layer_1 @ learned_weights_layer_2)  # here we do the projection\n",
        "#learned_weights_product = apply_threshold(learned_weights_product, 0.1)\n",
        "#learned_weights_product = apply_min_max_scaler(learned_weights_product)\n",
        "\n",
        "#plot_layer_receptive_fields(learned_weights_product.T)"
      ],
      "metadata": {
        "id": "jEFlg3u8dKmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learned_weights_layer_1 = get_weights(dbn_emnist, layer=0)\n",
        "#learned_weights_layer_2 = get_weights(dbn_emnist, layer=1)\n",
        "#learned_weights_layer_3 = get_weights(dbn_emnist, layer=2)\n",
        "\n",
        "#learned_weights_layer_1 = apply_threshold(learned_weights_layer_1, 0.1)\n",
        "#learned_weights_layer_2 = apply_threshold(learned_weights_layer_2, 0.1)\n",
        "#learned_weights_layer_3 = apply_threshold(learned_weights_layer_3, 0.1)\n",
        "\n",
        "#learned_weights_12_product = (learned_weights_layer_1 @ learned_weights_layer_2)  # here we do the projection\n",
        "#learned_weights_23_product = (learned_weights_12_product @ learned_weights_layer_3)  # here we do the projection\n",
        "#learned_weights_23_product = apply_threshold(learned_weights_23_product, 0.1)\n",
        "#learned_weights_23_product = apply_min_max_scaler(learned_weights_23_product)\n",
        "\n",
        "#plot_layer_receptive_fields(learned_weights_23_product.T)"
      ],
      "metadata": {
        "id": "fkhh5zwbdR5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:"
      ],
      "metadata": {
        "id": "HBiD9qjjWVZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using a clustering algorithm and computing the mean of the representation learned by each class we can also see which classes are closer from an internal representation standpoint.\n",
        "\n",
        "If the DBN is behaving as predicted, similar letters will have a similar internal representation and thus will be closer to each other.\n",
        "\n",
        "We can visualize this by using a dendogram."
      ],
      "metadata": {
        "id": "gwy6nOmaWS3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_kth_layer_repr(input, k, device):\n",
        "  flattened_input = input.view((input.shape[0], -1)).type(torch.FloatTensor).to(device)\n",
        "  hidden_repr, __ = dbn_emnist.rbm_layers[k].to_hidden(flattened_input)  # here we access the RBM object\n",
        "  return hidden_repr"
      ],
      "metadata": {
        "id": "bATFvpBsdVnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_repr_layer_1 = get_kth_layer_repr(emnist_train.data, 0, device)\n",
        "hidden_repr_layer_2 = get_kth_layer_repr(hidden_repr_layer_1, 1, device)\n",
        "hidden_repr_layer_3 = get_kth_layer_repr(hidden_repr_layer_2, 2, device)\n",
        "hidden_repr_layer_4 = get_kth_layer_repr(hidden_repr_layer_3, 3, device)"
      ],
      "metadata": {
        "id": "LxEruybvdvdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask(label):  # we use this function to filter by class\n",
        "  labels = emnist_train.targets.cpu().numpy()\n",
        "  return labels == label\n",
        "\n",
        "def get_label_to_mean_hidd_repr(hidden_representation):\n",
        "  hidden_representation_np = hidden_representation.cpu().numpy()\n",
        "  return {\n",
        "    label: hidden_representation_np[get_mask(label)].mean(axis=0)  # here we filter by class and compute the mean\n",
        "    for label in range(1,27)\n",
        "  }\n",
        "\n",
        "def get_hidden_reprs_matrix(hidden_representation):  # we use this to build the matrices\n",
        "  label_to_mean_hidd_repr = get_label_to_mean_hidd_repr(hidden_representation)\n",
        "  return np.concatenate(\n",
        "    [np.expand_dims(label_to_mean_hidd_repr[label], axis=0)  # here we adjust the shape of centroids to do the concat\n",
        "    for label in range(1,27)])"
      ],
      "metadata": {
        "id": "QzHFC9l4ddu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_hidd_repr_matrix_4 = get_hidden_reprs_matrix(hidden_repr_layer_4)"
      ],
      "metadata": {
        "id": "9ydcS04_dk1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dendrogram(mean_repr_matrix, title=\"\"):\n",
        "  fig, ax = plt.subplots()\n",
        "  linkage = cluster.hierarchy.linkage(mean_repr_matrix, method=\"complete\")  # we run the clustering algorithm here\n",
        "  dendrogram = cluster.hierarchy.dendrogram(linkage)\n",
        "  ax.set_title(title)"
      ],
      "metadata": {
        "id": "PBmBaHntd4kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dendrogram(mean_hidd_repr_matrix_4, \"Fourth hidden layer\")"
      ],
      "metadata": {
        "id": "3h0rGAMRd8H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a said earlier, a DBN network can be used to make prediction because it is a unsupervised learning tecnique.\n",
        "We can attach at each different layer a linear classifier and train it on the inputs given by the respective layer.\n",
        "\n",
        "If we see an improvement in the performances by using deeper layers it will mean that they managed to organize the information better."
      ],
      "metadata": {
        "id": "bcRNuoTmXGzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(torch.nn.Module):\n",
        "  def __init__(self, layer_size):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(layer_size, 27)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "Y0_TN2qIiSg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_size = dbn_emnist.rbm_layers[0].W.shape[1]\n",
        "linear1 = LinearModel(layer_size).to(device)\n",
        "\n",
        "layer_size = dbn_emnist.rbm_layers[1].W.shape[1]\n",
        "linear2 = LinearModel(layer_size).to(device)\n",
        "\n",
        "layer_size = dbn_emnist.rbm_layers[2].W.shape[1]\n",
        "linear3 = LinearModel(layer_size).to(device)\n",
        "\n",
        "layer_size = dbn_emnist.rbm_layers[3].W.shape[1]\n",
        "linear4 = LinearModel(layer_size).to(device)"
      ],
      "metadata": {
        "id": "6J5mcQmoiYCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(network, input, epochs=1500):\n",
        "  optimizer = torch.optim.SGD(network.parameters(), lr=0.05)\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = network(input).squeeze()\n",
        "    targets = emnist_train.targets.reshape(predictions.shape[0])  # here are the labels\n",
        "    loss = loss_fn(predictions, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"epoch : {:3d}/{}, loss = {:.4f}\".format(epoch + 1, epochs, loss))"
      ],
      "metadata": {
        "id": "6QAKZP5OicxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(linear1, hidden_repr_layer_1)"
      ],
      "metadata": {
        "id": "L3M2HEziiiHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(linear2, hidden_repr_layer_2)"
      ],
      "metadata": {
        "id": "Y41kXh1FilLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(linear3, hidden_repr_layer_3)"
      ],
      "metadata": {
        "id": "GQhucoGrinkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(linear4, hidden_repr_layer_4)"
      ],
      "metadata": {
        "id": "iuu-kHWjeUMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_repr_layer_1_test = get_kth_layer_repr(emnist_test.data, 0, device)\n",
        "hidden_repr_layer_2_test = get_kth_layer_repr(hidden_repr_layer_1_test, 1, device)\n",
        "hidden_repr_layer_3_test = get_kth_layer_repr(hidden_repr_layer_2_test, 2, device)\n",
        "hidden_repr_layer_4_test = get_kth_layer_repr(hidden_repr_layer_3_test, 3, device)"
      ],
      "metadata": {
        "id": "lzr6w7bhi0Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test1 = linear1(hidden_repr_layer_1_test)\n",
        "predictions_test2 = linear2(hidden_repr_layer_2_test)\n",
        "predictions_test3 = linear3(hidden_repr_layer_3_test)\n",
        "predictions_test4 = linear4(hidden_repr_layer_4_test)"
      ],
      "metadata": {
        "id": "J4cQTeaOi2jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(predictions_test, targets):\n",
        "  predictions_indices = predictions_test.max(axis=1).indices  # convert probabilities to indices\n",
        "  accuracy = (predictions_indices == targets).sum() / len(targets)\n",
        "  return accuracy.item()"
      ],
      "metadata": {
        "id": "SPTH3WoRi5v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(predictions_test1, emnist_test.targets)"
      ],
      "metadata": {
        "id": "dN9Z-jg0i6Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(predictions_test2, emnist_test.targets)"
      ],
      "metadata": {
        "id": "jeRMRKdii8_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(predictions_test3, emnist_test.targets)"
      ],
      "metadata": {
        "id": "dckwiOVIi-se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(predictions_test4, emnist_test.targets)"
      ],
      "metadata": {
        "id": "p4DYqbCVes2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there is a improvement in the performance of our linear read out.\n",
        "The more the original image is processed by the DBN the easier it becomes for him to do properly classify our data."
      ],
      "metadata": {
        "id": "IIeA0DJQ1wzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to compare these results, we will train now a deep feed forward network. This is a supervised learning tecnique that uses layers of connected formal neurons whose weights are optimized by using backpropagation.\n",
        "\n",
        "Backpropagation consists in trying to minimize a loss function (a measure on how wrong we are at predicting) by using gradient descent.\n",
        "\n",
        "In order to keep it fair, we want the number of epochs of training here to be equal to the sum of the epochs needed to both train the DBN and the linear read out."
      ],
      "metadata": {
        "id": "OtKCwDnvY3Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Feedforward(torch.nn.Module):\n",
        "  def __init__(self, first_hidden_layer_size, second_hidden_layer_size, third_hidden_layer_size):\n",
        "    super().__init__()\n",
        "    self.first_hidden = torch.nn.Linear(784, first_hidden_layer_size)\n",
        "    self.second_hidden = torch.nn.Linear(first_hidden_layer_size, second_hidden_layer_size)\n",
        "    self.third_hidden = torch.nn.Linear(second_hidden_layer_size, third_hidden_layer_size)\n",
        "    self.output = torch.nn.Linear(third_hidden_layer_size, 27)\n",
        "\n",
        "  def forward(self, input):\n",
        "    relu = torch.nn.ReLU()\n",
        "    first_hidden_repr = relu(self.first_hidden(input))\n",
        "    second_hidden_repr = relu(self.second_hidden(first_hidden_repr))\n",
        "    third_hidden_repr = relu(self.third_hidden(second_hidden_repr))\n",
        "    output = self.output(third_hidden_repr)\n",
        "    return output"
      ],
      "metadata": {
        "id": "xWCL2I_-1wMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffnn = Feedforward(400, 500, 800).to(device)"
      ],
      "metadata": {
        "id": "Tch7bwb710Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(ffnn, emnist_train.data.reshape((124800, 784)), epochs=1500)"
      ],
      "metadata": {
        "id": "z-yvmZAa13NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_ffnn = ffnn(emnist_test.data.reshape((20800, 784)))"
      ],
      "metadata": {
        "id": "ua6XNhmn20DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(predictions_ffnn, emnist_test.targets)"
      ],
      "metadata": {
        "id": "9LsEON3422iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:"
      ],
      "metadata": {
        "id": "KZNhIf3Ta6wS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to the the robustness of our models against noise (small random perturpations of our original input)."
      ],
      "metadata": {
        "id": "16Ef6IrUbSda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inject_noise(emnist_data, noise_level):\n",
        "  random_gaussian_tensor = torch.randn(emnist_data.shape, device=device)*noise_level\n",
        "  return emnist_data+random_gaussian_tensor\n",
        "  ### TASK: create a very simple function that adds some Gaussian noise (see torch.randn function) to the MNIST data"
      ],
      "metadata": {
        "id": "69odBI-W25qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_level = 0.3\n",
        "emnist_test_with_noise = inject_noise(emnist_test.data, noise_level)\n",
        "__ = plt.imshow(emnist_test_with_noise[1].reshape(28, 28).to(\"cpu\"), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "q7RRtw2o28aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After having defined a function capable of adding noise and checking that we got the desired results, we can compute the accuracy of our different models with different level of noise."
      ],
      "metadata": {
        "id": "Wu0jjgPbbvCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy_values_at_noise_level(noise_level):\n",
        "\n",
        "  mnist_test_with_noise = inject_noise(emnist_test.data, noise_level)  # first, let's create noisy test images\n",
        "\n",
        "  hidden_repr_layer_1_noisy = get_kth_layer_repr(mnist_test_with_noise, 0, device)  # here we compute the DBN representations\n",
        "  hidden_repr_layer_2_noisy = get_kth_layer_repr(hidden_repr_layer_1_noisy, 1, device)\n",
        "  hidden_repr_layer_3_noisy = get_kth_layer_repr(hidden_repr_layer_2_noisy, 2, device)\n",
        "  hidden_repr_layer_4_noisy = get_kth_layer_repr(hidden_repr_layer_3_noisy, 3, device)\n",
        "\n",
        "  predictions_first_hidden_noisy = linear1(hidden_repr_layer_1_noisy)  # here we use the previously-trained read-out classifiers\n",
        "  predictions_second_hidden_noisy = linear2(hidden_repr_layer_2_noisy)\n",
        "  predictions_third_hidden_noisy = linear3(hidden_repr_layer_3_noisy)\n",
        "  predictions_fourth_hidden_noisy = linear4(hidden_repr_layer_4_noisy)\n",
        "\n",
        "  accuracy_first_hidden = compute_accuracy(predictions_first_hidden_noisy, emnist_test.targets)\n",
        "  accuracy_second_hidden = compute_accuracy(predictions_second_hidden_noisy, emnist_test.targets)\n",
        "  accuracy_third_hidden = compute_accuracy(predictions_third_hidden_noisy, emnist_test.targets)\n",
        "  accuracy_fourth_hidden = compute_accuracy(predictions_fourth_hidden_noisy, emnist_test.targets)\n",
        "\n",
        "  ### TASK: repeat a similar process for the feed-forward model (NB: make sure you reshape the input data appropriately!)\n",
        "  predictions_ffnn_noisy = ffnn(emnist_test_with_noise.reshape((20800, 784)))\n",
        "  accuracy_ffnn=compute_accuracy(predictions_ffnn_noisy, emnist_test.targets)\n",
        "\n",
        "  return accuracy_first_hidden, accuracy_second_hidden, accuracy_third_hidden, accuracy_fourth_hidden, accuracy_ffnn"
      ],
      "metadata": {
        "id": "-Pz0o4aC2-9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#acc = get_accuracy_values_at_noise_level(0.6);\n",
        "#print(\"Accuracy of H1 read-out: %.3f\" % acc[0])\n",
        "#print(\"Accuracy of H2 read-out: %.3f\" % acc[1])\n",
        "#print(\"Accuracy of H3 read-out: %.3f\" % acc[2])\n",
        "#print(\"Accuracy of FF network : %.3f\" % acc[3])"
      ],
      "metadata": {
        "id": "kRRXEfBD3BIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_noise_robustness_curves(noise_levels):\n",
        "  accuracy_values_first_hidden = []\n",
        "  accuracy_values_second_hidden = []\n",
        "  accuracy_values_third_hidden = []\n",
        "  accuracy_values_fourth_hidden = []\n",
        "  accuracy_values_ffnn = []\n",
        "\n",
        "  for noise_level in noise_levels:\n",
        "    acc = get_accuracy_values_at_noise_level(noise_level)\n",
        "    accuracy_values_first_hidden.append(acc[0])\n",
        "    accuracy_values_second_hidden.append(acc[1])\n",
        "    accuracy_values_third_hidden.append(acc[2])\n",
        "    accuracy_values_fourth_hidden.append(acc[3])\n",
        "    accuracy_values_ffnn.append(acc[4])\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(range(len(noise_levels)), accuracy_values_first_hidden)\n",
        "  ax.plot(range(len(noise_levels)), accuracy_values_second_hidden)\n",
        "  ax.plot(range(len(noise_levels)), accuracy_values_third_hidden)\n",
        "  ax.plot(range(len(noise_levels)), accuracy_values_fourth_hidden)\n",
        "  ax.plot(range(len(noise_levels)), accuracy_values_ffnn)\n",
        "\n",
        "  ax.set_title(\"Robustness to noise\")\n",
        "  ax.set_xlabel(\"Noise level (%)\")\n",
        "  ax.set_ylabel(\"Accuracy\")\n",
        "  plt.xticks(range(len(noise_levels)), [int(l*100) for l in noise_levels])\n",
        "  plt.legend([\"First hidden\", \"Second hidden\", \"Third hidden\", \"Fourth hidden\" ,\"FFNN\"])"
      ],
      "metadata": {
        "id": "0iAtjaur3DvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_levels = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]\n",
        "plot_noise_robustness_curves(noise_levels)"
      ],
      "metadata": {
        "id": "QukXAOUX3Fn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adversarial attacks"
      ],
      "metadata": {
        "id": "Lj8t1bXD3F_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "5zLcxS403GoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DBNWithReadOut(torch.nn.Module):\n",
        "    def __init__(self, dbn_mnist, readouts, readout_level=0):\n",
        "        super().__init__()\n",
        "        self.readouts = readouts\n",
        "        self.dbn_mnist = dbn_mnist\n",
        "        self._require_grad()\n",
        "        self.readout_level = readout_level\n",
        "\n",
        "    def _require_grad(self):\n",
        "      for rbm in self.dbn_mnist.rbm_layers:\n",
        "        rbm.W.requires_grad_()\n",
        "        rbm.h_bias.requires_grad_()\n",
        "\n",
        "    def forward(self, image):\n",
        "      \"\"\"This forward pass uses probabilities instead of samples as RBM outputs\n",
        "       to backpropagate the gradient\"\"\"\n",
        "      p_v = image\n",
        "      hidden_states = []\n",
        "      for rbm in self.dbn_mnist.rbm_layers:\n",
        "        p_v = p_v.view((p_v.shape[0], -1))  # flatten\n",
        "        p_v, v = rbm(p_v)\n",
        "        hidden_states.append(p_v)\n",
        "      return self.readouts[self.readout_level].forward(hidden_states[self.readout_level])"
      ],
      "metadata": {
        "id": "CdWqvKWM3R0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_with_readout = DBNWithReadOut(dbn_emnist, [linear1, linear2, linear3], readout_level=2)"
      ],
      "metadata": {
        "id": "KKsDowF33T7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample_idx = 1\n",
        "test_image = emnist_test.data[test_sample_idx].reshape(1, 784)\n",
        "__ = plt.imshow(test_image.reshape(28,28).to('cpu'))"
      ],
      "metadata": {
        "id": "TDVmKlUk3WeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attacked_model = ffnn"
      ],
      "metadata": {
        "id": "MJOStHR23Zbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attacked_model = dbn_with_readout"
      ],
      "metadata": {
        "id": "VZitZnqt3bZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.requires_grad_()\n",
        "model_outputs = attacked_model(test_image)\n",
        "prediction = torch.argmax(model_outputs)\n",
        "print(f\"The prediction of the model for this clean sample is {prediction}.\")"
      ],
      "metadata": {
        "id": "Q1kPjHJH3dy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.2  # define strenght of the attack\n",
        "test_image_label = emnist_test.targets[test_sample_idx].unsqueeze(0)  # get ground truth label for that image\n",
        "loss_value = torch.nn.functional.cross_entropy(model_outputs, test_image_label)  # get loss value\n",
        "attacked_model.zero_grad()\n",
        "loss_value.backward()\n",
        "image_grad = test_image.grad.data  # get the gradient of the pixels w.r.t. the loss\n",
        "perturbed_image = fgsm_attack(test_image, epsilon, image_grad)\n",
        "\n",
        "perturbed_image_np = perturbed_image.detach().to('cpu').numpy()\n",
        "__ = plt.imshow(perturbed_image_np.reshape(28,28))"
      ],
      "metadata": {
        "id": "oUwYx3gf3gaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_outputs = attacked_model(perturbed_image.view((perturbed_image.shape[0], -1)))\n",
        "print(f\"The prediction of the model for the perturbed sample is {torch.argmax(model_outputs)}.\")"
      ],
      "metadata": {
        "id": "JL2GjS203ifm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yhb0nr93o_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_robustness_to_attack(model, device, test_loader, epsilon, num_steps=0, verbose=True):\n",
        "    correct = 0\n",
        "    print_reconstruction = num_steps > 0\n",
        "\n",
        "    for data, target in tqdm(test_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        data = data.reshape(-1, 784)\n",
        "        data.requires_grad = True  # Important for Attack\n",
        "\n",
        "        output = model.forward(data)\n",
        "\n",
        "        init_pred = torch.argmax(output)\n",
        "\n",
        "        if (print_reconstruction and verbose):\n",
        "          print(\"\\nHere's the original sample:\\n\")\n",
        "          plt.imshow(data[0].detach().to('cpu').numpy().reshape(28,28))\n",
        "          plt.show()\n",
        "\n",
        "        loss = functional.nll_loss(output, target)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = data.grad.data  # collect the gradient of the input data\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        if (print_reconstruction and verbose):\n",
        "            print(\"\\nHere's a perturbed sample:\\n\")\n",
        "            plt.imshow(perturbed_data[0].detach().to('cpu').numpy().reshape(28,28))\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        # If requested, reconstruct the input iterating forward-backward dynamics\n",
        "        if num_steps > 0:\n",
        "            for __ in range(0, num_steps):\n",
        "                perturbed_data, __ = model.dbn_mnist.reconstruct(perturbed_data)\n",
        "            if (print_reconstruction and verbose):\n",
        "                print(f\"\\nHere's what a {num_steps}-steps reconstructed sample looks like:\\n\")\n",
        "                plt.imshow(perturbed_data[0].detach().to('cpu').numpy().reshape(28,28))\n",
        "                plt.show()\n",
        "                print_reconstruction = False\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        # get the index of the max element in the output\n",
        "        final_pred = output.max(1, keepdim=True)[1]\n",
        "        final_pred = output.argmax(-1)\n",
        "        correct += (final_pred == target).sum()\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader.sampler))\n",
        "    print(\"\\nEpsilon: {}\\nTest Accuracy: {:.2f}%\\n\".format(epsilon, final_acc*100))\n",
        "\n",
        "    return final_acc.item()"
      ],
      "metadata": {
        "id": "bGsjUcTR3odn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    tv.datasets.MNIST('data/', train=False, download=False, transform=tv.transforms.Compose([tv.transforms.ToTensor()])),\n",
        "    batch_size=100, shuffle=True)"
      ],
      "metadata": {
        "id": "D1K-fgag3rfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_acc = test_robustness_to_attack(ffnn, device,\n",
        "                                      test_loader, epsilon=0.1,\n",
        "                                      num_steps=0"
      ],
      "metadata": {
        "id": "OBTuF-qj3tfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_acc = test_robustness_to_attack(dbn_with_readout, device,\n",
        "                                      test_loader, epsilon=0.1,\n",
        "                                      num_steps=0)"
      ],
      "metadata": {
        "id": "Y4FfaIGG3vnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TASK: do the same thing for the DBN with one top-down reconstruction step\n",
        "final_acc = test_robustness_to_attack(dbn_with_readout, device,\n",
        "                                      test_loader, epsilon=0.1,\n",
        "                                      num_steps=1)"
      ],
      "metadata": {
        "id": "90Y7YDi43xOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_values = [0, 0.05, 0.10, 0.15, 0.20, 0.25]\n",
        "\n",
        "def test_epsilon_values_effect(model, n_steps):\n",
        "  accuracies = list()\n",
        "\n",
        "  for eps in epsilon_values:\n",
        "      acc = test_robustness_to_attack(model, device, test_loader, eps, num_steps=n_steps, verbose=False)\n",
        "      accuracies.append(acc)\n",
        "\n",
        "  return accuracies"
      ],
      "metadata": {
        "id": "slVbOodz30SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "accuracies_ffnn = test_epsilon_values_effect(ffnn, n_steps=0)\n",
        "accuracies_dbn_0 = test_epsilon_values_effect(dbn_with_readout, n_steps=0)\n",
        "accuracies_dbn_1 = test_epsilon_values_effect(dbn_with_readout, n_steps=1)\n",
        "accuracies_dbn_2 = test_epsilon_values_effect(dbn_with_readout, n_steps=2)\n",
        "accuracies_dbn_3 = test_epsilon_values_effect(dbn_with_readout, n_steps=3)"
      ],
      "metadata": {
        "id": "TFnqNKFo32RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(9, 7), sharey=True)\n",
        "\n",
        "__ = ax.axhline(0.1, color='gray', linestyle=':')\n",
        "__ = ax.plot(epsilon_values, accuracies_ffnn)\n",
        "__ = ax.plot(epsilon_values, accuracies_dbn_0)\n",
        "__ = ax.plot(epsilon_values, accuracies_dbn_1)\n",
        "__ = ax.plot(epsilon_values, accuracies_dbn_2)\n",
        "__ = ax.plot(epsilon_values, accuracies_dbn_3)\n",
        "__ = ax.set_xlabel(\"Strength of adversarial attack ($\\epsilon$)\")\n",
        "__ = ax.set_ylabel(\"Accuracy\")\n",
        "__ = ax.set_title(\"Robustness to adversarial attacks\", {'fontsize': 15})\n",
        "__ = ax.legend([\"Chance level\", \"FFNN\", \"DBN\", \"DBN top-down\",\"DBN top-down x2\",\"DBN top-downx3\"])"
      ],
      "metadata": {
        "id": "gIIxdFJk34OX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}